# ğŸ§  NeuroInsight : A GNN + VLM + XAI Framework for 3D MRI Analysis & QnA
*A Graph Neural Network + Multimodal AI System for Brain Tumor Segmentation and Interpretation*

---

## ğŸ“– Overview

**NeuroInsight** is a deep learning web application that integrates a **Graph Neural Network (GNN)** for 3D MRI brain tumor segmentation with a **LLaVA Vision-Language model** for interactive interpretation.  
It transforms raw MRI scans (`.nii`/`.nii.gz`) into **graph-based tumor segmentation maps**, explains model predictions using **GNNExplainer**, and allows users to **chat with a multimodal AI assistant** about the scan.

---

## ğŸ§© Key Features

- âš™ï¸ **MRI to Graph Conversion** using supervoxel segmentation (SLIC) + Region Adjacency Graph (RAG)
- ğŸ§  **GNN-based segmentation** for identifying tumor subregions:
  - Background / Healthy tissue  
  - Necrotic Core  
  - Edema  
  - Enhancing Tumor
- ğŸ” **Explainable AI** using GNNExplainer (visualizes important nodes/edges)
- ğŸ’¬ **Interactive Chat** powered by **LLaVA** (via Ollama API) for radiology-style Q&A
- ğŸ›ï¸ **Streamlit Frontend** for an intuitive and visual workflow

---

## ğŸ§± Architecture Overview

             
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚      3D FLAIR MRI (.nii)    â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
               ğŸ§© Preprocessing & Graph Building
               - Normalize MRI intensity
               - Apply SLIC â†’ Supervoxels
               - Build RAG â†’ Nodes + Edges
               - Extract node features:
                 [Intensity, Size, Centroid (x,y,z)]
                            â”‚
                            â–¼
                     ğŸ§  Graph Neural Network
               (GCNConv Layers + BatchNorm + Dropout)
               - Learns relationships between regions
               - Classifies each node into tumor types
                            â”‚
                            â–¼
                      ğŸ” GNN Explainer
               - Highlights important nodes/edges
               - Generates interpretable subgraph
                            â”‚
                            â–¼
                 ğŸ§¾ Classification Summary (by Node)
               - Background / Healthy %
               - Necrotic Core %
               - Edema %
               - Enhancing Tumor %
                            â”‚
                            â–¼
                  ğŸ–¼ï¸ 2D MRI Visualization
                            â”‚
                            â–¼
                 ğŸ’¬ LLaVA Vision-Language Chat
               - Image + GNN summary fed to LLaVA
               - Multimodal Q&A about the scan

---

## âš™ï¸ Model Architecture

###  **Graph Convolutional Network (GCN)**

| Layer | Type | Input â†’ Output | Purpose |
|--------|------|----------------|----------|
| 1 | GCNConv | 5 â†’ 32 | Extract local region features |
| 2 | GCNConv | 32 â†’ 16 | Aggregate neighborhood context |
| 3 | GCNConv | 16 â†’ 5 | Classify each node (0â€“4 classes) |

**Activation:** ReLU  
**Normalization:** BatchNorm1d  
**Regularization:** Dropout (p=0.5)  
**Output:** `log_softmax` per node

### ğŸ§© Classes

| Label | Meaning | Description |
|--------|----------|--------------|
| 0 | Background / Healthy | Normal brain tissue |
| 1 | Necrotic Core | Dead tissue in tumor center |
| 2 | Edema | Peritumoral swelling |
| 4 | Enhancing Tumor | Active proliferating tumor |

---

## ğŸ”¬ Data Flow

1. **Input:** `.nii` MRI file  
2. **Processing:**
   - Convert MRI volume â†’ normalized array  
   - Generate supervoxels (`slic`)  
   - Build adjacency graph (`rag_mean_color`)  
   - Create PyTorch Geometric `Data(x, edge_index, pos)`  
3. **Inference:**  
   - Model predicts per-node tumor class  
   - GNNExplainer computes feature/edge importance  
4. **Output:**  
   - Node-level segmentation summary  
   - Explanation graph  
   - 2D slice preview  
5. **LLaVA Integration:**  
   - GNN summary + image â†’ LLaVA via Ollama API  
   - User can query scan in natural language  

---

## ğŸ“Š Evaluation Metrics

| Metric | Formula | Description |
|---------|----------|--------------|
| **Accuracy** | (TP + TN) / (All) | Fraction of correctly classified nodes |
| **Dice Score (F1)** | 2TP / (2TP + FP + FN) | Measures overlap between predicted & actual tumor |
| **IoU (Jaccard)** | TP / (TP + FP + FN) | Measures intersection-over-union |
| **Precision / Recall** | Standard metrics per class | Identify sensitivity vs specificity |

---

## ğŸ’¬ Multimodal Integration (LLaVA via Ollama)

After segmentation:
- A **2D MRI slice** and the **GNN summary text** are encoded and sent to **LLaVA**.
- The assistant answers user queries such as:
  - â€œWhere is the tumor located?â€
  - â€œIs it enhancing or necrotic?â€
  - â€œWhat percentage of tissue is affected?â€

This allows **multimodal reasoning** â€” image + text understanding, similar to an AI radiologistâ€™s assistant.

---

## ğŸ–¥ï¸ Streamlit Web App

### ğŸ›ï¸ User Interface
| Section | Function |
|----------|-----------|
| **1. GNN Analysis** | Upload MRI, run segmentation, view GNN summary & explainer graphs |
| **2. LLaVA Chat** | Chat with the multimodal assistant about scan results |

---

# Built for the intersection of medical imaging and graph intelligence â€” combining neuroscience, deep learning, and natural language reasoning.
